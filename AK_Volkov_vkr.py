# -*- coding: utf-8 -*-
"""Volkov_AK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T6DOJZc0qXFTZaxAOt7C7_0f2CVWIrBs
"""

# -*- coding: utf-8 -*-

import pandas as pd
import numpy as np
import networkx as nx
from datetime import datetime, timedelta
import random
import matplotlib.pyplot as plt
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import RobustScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import sqlite3
import os
import argparse

def generate_network_data(num_records=100000, start_date="2023-01-01", end_date="2025-03-28"):
    services = ["HTTP", "HTTPS", "SSH", "FTP", "DNS", "SMTP", "ICMP"]
    mac_prefixes = ["00:1A:79", "00:0D:3A", "00:24:BE"]
    ip_ranges = ["192.168.1.", "10.0.0.", "172.16.0."]
    device_types = ["Smartphone", "Laptop", "IoT", "Tablet"]

    start = datetime.strptime(start_date, "%Y-%m-%d")
    end = datetime.strptime(end_date, "%Y-%m-%d")

    data = pd.DataFrame({
        "Timestamp": [start + timedelta(seconds=random.randint(0, int((end - start).total_seconds())))
                     for _ in range(num_records)],
        "WAN IP": [f"{random.choice(ip_ranges)}{random.randint(1, 254)}" for _ in range(num_records)],
        "MAC Address": [f"{random.choice(mac_prefixes)}:{random.randint(0, 255):02X}:{random.randint(0, 255):02X}:{random.randint(0, 255):02X}"
                       for _ in range(num_records)],
        "Service": np.random.choice(services, num_records),
        "Time Spent (s)": np.random.randint(1, 3600, num_records),
        "Traffic Volume (MB)": np.round(np.random.uniform(0.1, 500, num_records), 2),
        "Device_Type": np.random.choice(device_types, num_records),
        "Signal_Strength": np.random.randint(-90, -30, num_records)
    })

    anomaly_mask = np.random.rand(num_records) < 0.05
    data.loc[anomaly_mask, 'Time Spent (s)'] = np.random.randint(3600, 86400, sum(anomaly_mask))
    data.loc[anomaly_mask, 'Traffic Volume (MB)'] = np.random.uniform(1000, 5000, sum(anomaly_mask))
    data.loc[anomaly_mask, 'Service'] = np.random.choice(["SSH", "FTP", "ICMP"], sum(anomaly_mask))
    data['Label'] = 0
    data.loc[anomaly_mask, 'Label'] = 1

    return data

def load_and_prepare_data(filepath):
    df = pd.read_csv(filepath)
    if 'Label' not in df.columns:
        print("Label column not found, regenerating dataset.")
        df = generate_network_data()
        df.to_csv(filepath, index=False)
    df = df[(df['Time Spent (s)'] > 0) & (df['Traffic Volume (MB)'] >= 0)]
    df['Timestamp'] = pd.to_datetime(df['Timestamp'])
    df['Hour_sin'] = np.sin(2*np.pi*df['Timestamp'].dt.hour/24)
    df['Hour_cos'] = np.cos(2*np.pi*df['Timestamp'].dt.hour/24)
    return df

def generate_features(df):
    df['Traffic_per_connection'] = df['Traffic Volume (MB)'] / (df['Time Spent (s)'] + 1e-6)
    return df.fillna(0)

class AnomalyDetector:
    def __init__(self):
        self.model = make_pipeline(
            RobustScaler(),
            IsolationForest(n_estimators=500, contamination=0.05, random_state=42)
        )

    def fit(self, X):
        self.model.fit(X)

    def predict(self, X):
        return (self.model.predict(X) < 0).astype(int)

def plot_3d_anomalies(df, anomalies):
    fig = plt.figure(figsize=(12, 8))
    ax = fig.add_subplot(111, projection='3d')

    normal = df[~anomalies.astype(bool)]
    anomaly = df[anomalies.astype(bool)]

    ax.scatter(normal['Time Spent (s)'], normal['Traffic Volume (MB)'], normal['Traffic_per_connection'], c='blue', alpha=0.3, label='Normal')
    ax.scatter(anomaly['Time Spent (s)'], anomaly['Traffic Volume (MB)'], anomaly['Traffic_per_connection'], c='red', alpha=0.7, label='Anomaly')

    ax.set_xlabel('Time Spent (s)')
    ax.set_ylabel('Traffic (MB)')
    ax.set_zlabel('Traffic per Conn')
    plt.legend()
    plt.show()

def pairwise_plot(df, features, labels):
    plot_df = df[features].copy()
    plot_df['Label'] = labels
    sns.pairplot(plot_df, hue='Label', palette={0: 'blue', 1: 'red'}, plot_kws={'alpha': 0.5})
    plt.show()

def main(mode='analyze'):
    if not os.path.exists("data.csv"):
        df = generate_network_data()
        df.to_csv("data.csv", index=False)

    df = load_and_prepare_data("data.csv")
    df = generate_features(df)

    features = ['Time Spent (s)', 'Traffic Volume (MB)', 'Traffic_per_connection', 'Hour_sin', 'Hour_cos']
    X = df[features]
    y = df['Label']

    if mode == 'analyze':
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

        detector = AnomalyDetector()
        detector.fit(X_train)
        y_pred = detector.predict(X_test)

        print("\nClassification Report:")
        print(classification_report(y_test, y_pred))
        print("\nConfusion Matrix:")
        print(confusion_matrix(y_test, y_pred))

        plot_3d_anomalies(df.iloc[X_test.index], y_pred)
        pairwise_plot(df.iloc[X_test.index], features, y_pred)

if __name__ == "__main__":
    import sys
    if hasattr(sys, 'argv') and any(arg.startswith('--mode') for arg in sys.argv):
        parser = argparse.ArgumentParser()
        parser.add_argument('--mode', choices=['analyze'], default='analyze')
        args = parser.parse_args()
        main(mode=args.mode)
    else:
        main(mode='analyze')